{
    "cumulative_timesteps": 300012,
    "cumulative_model_updates": 14,
    "policy_average_reward": 0.0040792710327587,
    "epoch": 5,
    "ts_since_last_save": 100000,
    "reward_running_stats": {
        "mean": [
            -0.027808647602796555
        ],
        "var": [
            47.555946350097656
        ],
        "shape": [
            1
        ],
        "count": 900
    },
    "wandb_run_id": "y57eaj0u",
    "wandb_project": "rlgym-ppo",
    "wandb_entity": "",
    "wandb_group": "unnamed-runs",
    "wandb_config": {
        "n_proc": 8,
        "min_inference_size": 7,
        "timestep_limit": 1000000000,
        "exp_buffer_size": 150000,
        "ts_per_iteration": 50000,
        "standardize_returns": true,
        "standardize_obs": false,
        "policy_layer_sizes": [
            256,
            256,
            256
        ],
        "critic_layer_sizes": [
            256,
            256,
            256
        ],
        "ppo_epochs": 1,
        "ppo_batch_size": 50000,
        "ppo_minibatch_size": 50000,
        "ppo_ent_coef": 0.001,
        "ppo_clip_range": 0.2,
        "gae_lambda": 0.95,
        "gae_gamma": 0.99,
        "policy_lr": 0.0003,
        "critic_lr": 0.0003,
        "shm_buffer_size": 8192
    }
}